{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dd8de4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType , StructField, StringType, IntegerType, DataType , FloatType , TimestampType\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7fb129",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "catalog_name = 'ecommerce'\n",
    "\n",
    "#define schema for the raw data file for brand\n",
    "brand_schema = StructType([\n",
    "    StructField('brand_code', StringType(), False),\n",
    "    StructField('brand_name', StringType(), True),\n",
    "    StructField('category_code', StringType(), True),\n",
    "    ])\n",
    "\n",
    "raw_data_source = '/Volumes/ecommerce/source_data/raw/brands/*.csv'\n",
    "\n",
    "df = spark.read.option(\"header\",\"True\").option(\"delimiter\",\",\").schema(brand_schema).csv(raw_data_source)\n",
    "\n",
    "#add metadata columns\n",
    "df = df.withColumn(\"_source_file\",F.col(\"_metadata.file_path\")).withColumn(\"ingested_at\",F.current_timestamp())\n",
    "\n",
    "display(df.limit(5))\n",
    "\n",
    "\n",
    "#writing dataframe to delta table\n",
    "df.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "        .option(\"mergeSchema\", \"true\") \\\n",
    "            .saveAsTable(f\"{catalog_name}.bronze.brz_brands\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec991a74",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#define schema for the raw data file for category\n",
    "category_schema = StructType([\n",
    "    StructField('category_code', StringType(), False),\n",
    "    StructField('category_name', StringType(), True),\n",
    "    ])\n",
    "raw_data_source = '/Volumes/ecommerce/source_data/raw/category/*.csv'\n",
    "\n",
    "df = spark.read.option(\"header\",\"True\").option(\"delimiter\",\",\").schema(category_schema).csv(raw_data_source)\n",
    "\n",
    "#add metadata columns\n",
    "df = df.withColumn(\"_source_file\",F.col(\"_metadata.file_path\")).withColumn(\"ingested_at\",F.current_timestamp())\n",
    "\n",
    "display(df.limit(5))\n",
    "df.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "        .option(\"mergeSchema\", \"true\") \\\n",
    "            .saveAsTable(f\"{catalog_name}.bronze.brz_category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b84234",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#define schema for the raw data file for customers\n",
    "customers_schema = StructType([\n",
    "    StructField('customer_id', StringType(), False),\n",
    "    StructField('phone', FloatType(), True),\n",
    "    StructField('country_code', StringType(), True),\n",
    "    StructField('country', StringType(), True),\n",
    "    StructField('state', StringType(), True),\n",
    "    ])\n",
    "\n",
    "raw_data_source = '/Volumes/ecommerce/source_data/raw/customers/*.csv'\n",
    "\n",
    "df = spark.read.option(\"header\",\"True\").option(\"delimiter\",\",\").schema(customers_schema).csv(raw_data_source)\n",
    "\n",
    "#add metadata columns\n",
    "df = df.withColumn(\"_source_file\",F.col(\"_metadata.file_path\")).withColumn(\"ingested_at\",F.current_timestamp())\n",
    "\n",
    "display(df.limit(5))\n",
    "\n",
    "df.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "        .option(\"mergeSchema\", \"true\") \\\n",
    "            .saveAsTable(f\"{catalog_name}.bronze.brz_customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3248e5b3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#define schema for the raw data file for date\n",
    "date_schema = StructType([\n",
    "    StructField('date', StringType(), False),\n",
    "    StructField('year', IntegerType(), True),\n",
    "    StructField('day_name', StringType(), True),\n",
    "    StructField('quarter', IntegerType(), True),\n",
    "    StructField('week_of_year', IntegerType(), True),\n",
    "    ])\n",
    "\n",
    "raw_data_source = '/Volumes/ecommerce/source_data/raw/date/*.csv'\n",
    "\n",
    "df = spark.read.option(\"header\",\"True\").option(\"delimiter\",\",\").schema(date_schema).csv(raw_data_source)\n",
    "\n",
    "#add metadata columns\n",
    "df = df.withColumn(\"_source_file\",F.col(\"_metadata.file_path\")).withColumn(\"ingested_at\",F.current_timestamp())\n",
    "\n",
    "display(df.limit(5))\n",
    "df.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "        .option(\"mergeSchema\", \"true\") \\\n",
    "            .saveAsTable(f\"{catalog_name}.bronze.brz_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75deea40",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#define schema for the raw data file for order\n",
    "order_schema = StructType([\n",
    "    StructField('dt', StringType(), True),\n",
    "    StructField('order_ts', TimestampType(), True),\n",
    "    StructField('customer_id', StringType(), True),\n",
    "    StructField('order_id', IntegerType(), False),\n",
    "    StructField('item_seq', IntegerType(), True),\n",
    "    StructField('product_id', StringType(), False),\n",
    "    StructField('quantity', IntegerType(), True),\n",
    "    StructField('unit_price_currency', StringType(), True),\n",
    "    StructField('unit_price', FloatType(), True),\n",
    "    StructField('discount_pct', StringType(), True),\n",
    "    StructField('tax_amount', FloatType(), True),\n",
    "    StructField('channel', StringType(), True),\n",
    "    StructField('coupon_code', StringType(), True),\n",
    "    ])\n",
    "raw_data_source = '/Volumes/ecommerce/source_data/raw/order_items/landing/*.csv'\n",
    "\n",
    "df = spark.read.option(\"header\",\"True\").option(\"delimiter\",\",\").schema(order_schema).csv(raw_data_source)\n",
    "\n",
    "#add metadata columns\n",
    "df = df.withColumn(\"_source_file\",F.col(\"_metadata.file_path\")).withColumn(\"ingested_at\",F.current_timestamp())\n",
    "\n",
    "display(df.limit(5))\n",
    "\n",
    "df.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "        .option(\"mergeSchema\", \"true\") \\\n",
    "            .saveAsTable(f\"{catalog_name}.bronze.brz_orders\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ef6218",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#define schema for the raw data file for product\n",
    "product_schema = StructType([\n",
    "    StructField('product_id', StringType(), False),\n",
    "    StructField('sku', StringType(), True),\n",
    "    StructField('category_code', StringType(), True),\n",
    "    StructField('brand_code', StringType(), True),\n",
    "    StructField('color', StringType(), True),\n",
    "    StructField('size', StringType(), False),\n",
    "    StructField('material', StringType(), True),\n",
    "    StructField('weight_grams', StringType(), True),\n",
    "    StructField('length_cm', StringType(), True),\n",
    "    StructField('width_cm', FloatType(), True),\n",
    "    StructField('height_cm', FloatType(), True),\n",
    "    StructField('rating_count', IntegerType(), True),\n",
    "    ])\n",
    "    \n",
    "raw_data_source = '/Volumes/ecommerce/source_data/raw/products/*.csv'\n",
    "\n",
    "df = spark.read.option(\"header\",\"True\").option(\"delimiter\",\",\").schema(product_schema).csv(raw_data_source)\n",
    "\n",
    "#add metadata columns\n",
    "df = df.withColumn(\"_source_file\",F.col(\"_metadata.file_path\")).withColumn(\"ingested_at\",F.current_timestamp())\n",
    "\n",
    "display(df.limit(5))\n",
    "\n",
    "df.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "        .option(\"mergeSchema\", \"true\") \\\n",
    "            .saveAsTable(f\"{catalog_name}.bronze.brz_products\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
